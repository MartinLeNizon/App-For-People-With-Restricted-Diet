{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergens = {\n",
    "    \"gluten\": 0,\n",
    "    \"eggs\": 1,\n",
    "    \"milk\": 2,\n",
    "    \"nuts\": 3,\n",
    "    \"peanuts\": 4,\n",
    "    \"soja\": 5,\n",
    "    \"molluscs\": 6,\n",
    "    \"fish\": 7,\n",
    "    \"lupin\": 8,\n",
    "    \"crustaceans\": 9,\n",
    "    \"sesame\": 10,\n",
    "    \"mustard\": 11,\n",
    "    \"celery\": 12,\n",
    "    \"sulphites\": 13\n",
    "}\n",
    "\n",
    "nb_allergens = len(allergens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CLIP = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor_CLIP = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_CLIP(image, allergen):\n",
    "    image = Image.open(image)\n",
    "    match allergen:\n",
    "        case 0:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing wheat or gluten\", \"ingredient list of a product without wheat nor gluten\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 1:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing eggs\", \"ingredient list of a product without eggs\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 2:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing milk\", \"ingredient list of a product without milk\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 3:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing nuts\", \"ingredient list of a product without nuts\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 4:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing peanuts\", \"ingredient list of a product without peanuts\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 5:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing soya\", \"ingredient list of a product without soya\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 6:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing molluscs\", \"ingredient list of a product without molluscs\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 7:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing fish\", \"ingredient list of a product without fish\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 8:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing lupin\", \"ingredient list of a product without lupin\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 9:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing crustaceans\", \"ingredient list of a product without crustaceans\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 10:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing sesame\", \"ingredient list of a product without sesame\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 11:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing mustard\", \"ingredient list of a product without mustard\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 12:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing celery\", \"ingredient list of a product without celery\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        case 13:\n",
    "            inputs = processor_CLIP(text=[\"ingredient list of a product containing sulphites\", \"ingredient list of a product without sulphites\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    outputs = model_CLIP(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "    probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "\n",
    "    return round(probs[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_allergens_CLIP(image):\n",
    "    prediction = []\n",
    "    for allergen in range(0, 14):\n",
    "        prediction.append(predict_CLIP(image, allergen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EasyOCR Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'], gpu=False)  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_allergens_EasyOCR(image):\n",
    "    # ------------ Extract text ---------------------\n",
    "    image_path = 'CLIP/feature_engineering_dataset/enhanced_data/002.jpg'\n",
    "    result = reader.readtext(image_path)\n",
    "    text = ' '.join(item[1] for item in result)\n",
    "    text = text.lower()\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    prediction = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    print(text)\n",
    "\n",
    "    if \"gluten\" in text or \"wheat\" in text:\n",
    "        prediction[allergens['gluten']] = 1\n",
    "    if \"egg\" in text:\n",
    "        prediction[allergens['eggs']] = 1\n",
    "    if \"milk\" in text or \"whey\" in text:\n",
    "        prediction[allergens['milk']] = 1\n",
    "    if \"nut\" in text:\n",
    "        prediction[allergens['nuts']] = 1\n",
    "    if \"peanut\" in text:\n",
    "        prediction[allergens['peanuts']] = 1\n",
    "    if \"soja\" in text or \"soy\" in text:\n",
    "        prediction[allergens['soja']] = 1\n",
    "    if \"mollusc\" in text:\n",
    "        prediction[allergens['molluscs']] = 1\n",
    "    if \"fish\" in text or \"tuna\" in text or \"salmon\" in text or \"cod\" in text or \"tilapia\" in text or \"sardine\" in text:\n",
    "        prediction[allergens['fish']] = 1\n",
    "    if \"lupin\" in text:\n",
    "        prediction[allergens['lupin']] = 1\n",
    "    if \"crustacean\" in text:\n",
    "        prediction[allergens['crustaceans']] = 1\n",
    "    if \"sesame\" in text:\n",
    "        prediction[allergens['sesame']] = 1\n",
    "    if \"mustard\" in text:\n",
    "        prediction[allergens['mustard']] = 1\n",
    "    if \"celery\" in text:\n",
    "        prediction[allergens['celery']] = 1\n",
    "    if \"sulphite\" in text:\n",
    "        prediction[allergens['sulphites']] = 1\n",
    "        print(\"hey\")\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nizon\\AppData\\Local\\Temp\\ipykernel_5352\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gluten</th>\n",
       "      <th>egg</th>\n",
       "      <th>milk</th>\n",
       "      <th>nuts</th>\n",
       "      <th>peanuts</th>\n",
       "      <th>soya</th>\n",
       "      <th>molluscs</th>\n",
       "      <th>fish</th>\n",
       "      <th>lupin</th>\n",
       "      <th>crustaceans</th>\n",
       "      <th>sesame</th>\n",
       "      <th>mustard</th>\n",
       "      <th>celery</th>\n",
       "      <th>sulphites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gluten  egg  milk  nuts  peanuts  soya  molluscs  fish  lupin  \\\n",
       "0       1.0  1.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "1       1.0  1.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "2       1.0  1.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "3       1.0  1.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "4       1.0  1.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "..      ...  ...   ...   ...      ...   ...       ...   ...    ...   \n",
       "214     0.0  0.0   1.0   1.0      1.0   1.0       0.0   0.0    0.0   \n",
       "215     0.0  0.0   0.0   0.0      0.0   0.0       0.0   0.0    0.0   \n",
       "216     0.0  0.0   1.0   0.0      0.0   0.0       0.0   0.0    0.0   \n",
       "217     0.0  0.0   1.0   0.0      0.0   1.0       0.0   0.0    0.0   \n",
       "218     1.0  0.0   1.0   1.0      0.0   1.0       0.0   0.0    0.0   \n",
       "\n",
       "     crustaceans  sesame  mustard  celery  sulphites  \n",
       "0            0.0     0.0      0.0     0.0        1.0  \n",
       "1            0.0     0.0      0.0     0.0        0.0  \n",
       "2            0.0     0.0      0.0     0.0        0.0  \n",
       "3            0.0     0.0      0.0     0.0        0.0  \n",
       "4            0.0     0.0      0.0     0.0        0.0  \n",
       "..           ...     ...      ...     ...        ...  \n",
       "214          0.0     0.0      0.0     0.0        0.0  \n",
       "215          0.0     0.0      0.0     0.0        0.0  \n",
       "216          0.0     0.0      0.0     0.0        0.0  \n",
       "217          0.0     0.0      0.0     0.0        0.0  \n",
       "218          0.0     0.0      0.0     0.0        0.0  \n",
       "\n",
       "[219 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file = pd.read_excel('labellisation.xlsx')\n",
    "excel_file = excel_file.iloc[0:219, 1:15]\n",
    "\n",
    "excel_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5352\\2343700682.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprediction_CLIP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_allergens_CLIP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mdatasets/raw_dataset/\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m03d\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.jpg\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresults_CLIP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_CLIP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_CLIP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mresults_CLIP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6289\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6290\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6291\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "results_CLIP = pd.DataFrame()\n",
    "\n",
    "for image in range(1, 21):\n",
    "    prediction_CLIP = predict_allergens_CLIP(f\"datasets/raw_dataset/{image:03d}.jpg\")\n",
    "    \n",
    "results_CLIP = results_CLIP.append(pd.Series(prediction_CLIP, name=f\"{image}\"))\n",
    "\n",
    "results_CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
